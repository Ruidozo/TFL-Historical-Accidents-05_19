version: '3.8'

services:
  # PostgreSQL for Airflow metadata
  airflow_postgres:
    image: postgres:13
    container_name: airflow_postgres
    environment:
      POSTGRES_USER: ${AIRFLOW_POSTGRES_USER}
      POSTGRES_PASSWORD: ${AIRFLOW_POSTGRES_PASSWORD}
      POSTGRES_DB: ${AIRFLOW_DB}
    ports:
      - "5232:5432"
    volumes:
      - airflow_metadata:/var/lib/postgresql/data

  # PostgreSQL for project data
  postgres_db_tfl_accident_data:
    image: postgres:15
    container_name: postgres_db_tfl_accident_data
    restart: always
    env_file:
      - .env
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
    ports:
      - "5433:5432"
    volumes:
      - postgres_db_data:/var/lib/postgresql/data
      - ./db_init.sh:/docker-entrypoint-initdb.d/db_init.sh
      - ./.env:/.env

  # Airflow Webserver
  airflow-webserver:
    build: ./airflow
    container_name: airflow_webserver-tfl
    restart: always
    depends_on:
      - airflow_postgres
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${AIRFLOW_POSTGRES_USER}:${AIRFLOW_POSTGRES_PASSWORD}@airflow_postgres:5432/${AIRFLOW_DB}
      GOOGLE_APPLICATION_CREDENTIALS: /opt/airflow/keys/gcp_credentials.json
      LOCAL_STORAGE: /opt/airflow/processed_data/raw/csv
    ports:
      - "8082:8080"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
      - airflow_plugins:/opt/airflow/plugins
      - ./airflow/dags/dbt:/usr/app/dbt  
      - ./airflow/dags/dlt:/usr/app/dlt  
      - ./secrets/gcp_credentials.json:/opt/airflow/keys/gcp_credentials.json:ro
      - ./airflow/dags/dbt/logs:/usr/app/dbt/logs
    command: ["airflow", "webserver"]

  # Airflow Scheduler
  airflow-scheduler:
    build: ./airflow
    container_name: airflow_scheduler
    restart: always
    depends_on:
      - airflow-webserver
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${AIRFLOW_POSTGRES_USER}:${AIRFLOW_POSTGRES_PASSWORD}@airflow_postgres:5432/${AIRFLOW_DB}
      GOOGLE_APPLICATION_CREDENTIALS: /opt/airflow/keys/gcp_credentials.json
      LOCAL_STORAGE: /opt/airflow/processed_data/raw/csv
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
      - airflow_plugins:/opt/airflow/plugins
      - ./airflow/dags/dbt:/usr/app/dbt  
      - ./airflow/dags/dlt:/usr/app/dlt  
      - ./secrets/gcp_credentials.json:/opt/airflow/keys/gcp_credentials.json:ro
      - ./airflow/dags/dbt/logs:/usr/app/dbt/logs
    command: ["airflow", "scheduler"]

  # âœ… Streamlit Dashboard
  dashboard:
    build: ./dashboard
    container_name: dashboard
    restart: always
    depends_on:
      - postgres_db_tfl_accident_data
    env_file:
      - .env
    ports:
      - "8501:8501"
    volumes:
      - ./dashboard:/usr/app/dashboard
      - ./.env:/usr/app/.env
    working_dir: /usr/app/dashboard
    command: ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]

volumes:
  airflow_metadata:
  postgres_db_data:
  airflow_logs:
  airflow_plugins:
  secrets: